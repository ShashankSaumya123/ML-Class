{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Code ML.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wy90M9wlhLXD"
      },
      "source": [
        "#IMPORTING STUFFS\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "import pandas as pd \n",
        "from skimage.io import imread, imshow\n",
        "from skimage.transform import rescale\n",
        "from os import listdir\n",
        "from sklearn.model_selection import train_test_split as tts"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPlvimq5fkDH"
      },
      "source": [
        "class My_Custom_Generator(keras.utils.Sequence) :\n",
        "  \n",
        "  def __init__(self, image_filenames, labels, batch_size) :\n",
        "    self.image_filenames = image_filenames\n",
        "    self.labels = labels\n",
        "    self.batch_size = batch_size\n",
        "    \n",
        "    \n",
        "  def __len__(self) :\n",
        "    return (np.ceil(len(self.image_filenames) / float(self.batch_size))).astype(np.int)\n",
        "  \n",
        "  \n",
        "  def __getitem__(self, idx) :\n",
        "    batch_x = self.image_filenames[idx * self.batch_size : (idx+1) * self.batch_size]\n",
        "    batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\n",
        "    \n",
        "    return np.array(batch_x), np.array(batch_y)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFMaOTjehN6L"
      },
      "source": [
        "#GETTING DATA\n",
        "X = []\n",
        "Y = []\n",
        "for filename in listdir('/content/drive/MyDrive/WBC_data_kaggle/main_dataset/test/EOSINOPHIL'):\n",
        "    # load image\n",
        "    img_data = imread('/content/drive/MyDrive/WBC_data_kaggle/main_dataset/test/EOSINOPHIL/' + filename,as_gray=True)\n",
        "    #Rescaling the image\n",
        "    image_r = rescale(img_data, 0.5, anti_aliasing=False)\n",
        "    X.append(image_r)\n",
        "    Y.append(0)\n",
        "\n",
        "for filename in listdir('/content/drive/MyDrive/WBC_data_kaggle/main_dataset/test/LYMPHOCYTE'):\n",
        "    # load image\n",
        "    img_data = imread('/content/drive/MyDrive/WBC_data_kaggle/main_dataset/test/LYMPHOCYTE/' + filename,as_gray=True)\n",
        "    #Rescaling the image\n",
        "    image_r = rescale(img_data, 0.5, anti_aliasing=False)\n",
        "    X.append(image_r)\n",
        "    Y.append(1)\n",
        "\n",
        "for filename in listdir('/content/drive/MyDrive/WBC_data_kaggle/main_dataset/test/MONOCYTE'):\n",
        "    # load image\n",
        "    img_data = imread('/content/drive/MyDrive/WBC_data_kaggle/main_dataset/test/MONOCYTE/' + filename,as_gray=True)\n",
        "    #Rescaling the image\n",
        "    image_r = rescale(img_data, 0.5, anti_aliasing=False)\n",
        "    X.append(image_r)\n",
        "    Y.append(2)\n",
        "\n",
        "for filename in listdir('/content/drive/MyDrive/WBC_data_kaggle/main_dataset/test/NEUTROPHIL'):\n",
        "    # load image\n",
        "    img_data = imread('/content/drive/MyDrive/WBC_data_kaggle/main_dataset/test/NEUTROPHIL/' + filename,as_gray=True)\n",
        "    #Rescaling the image\n",
        "    image_r = rescale(img_data, 0.5, anti_aliasing=False)\n",
        "    X.append(image_r)\n",
        "    Y.append(3)\n",
        "\n",
        "X_arr = np.array(X)\n",
        "Y_arr = np.array(Y)\n",
        "\n",
        "X_fi,Y_fi = shuffle(X_arr,Y_arr)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5l5oMRebhao7",
        "outputId": "af66e44a-8c31-4949-9dde-4ca1f4af9d90"
      },
      "source": [
        "print(X_fi.shape)\n",
        "print(Y_fi.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(600, 120, 160)\n",
            "(600,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHgQGUnGhca4"
      },
      "source": [
        "X_train, X_test, y_train, y_test = tts(X_fi, Y_fi, test_size=0.33)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4ArSgzYheGc"
      },
      "source": [
        "#RESHAPING TO PASS THE ARRAY TO CNN\n",
        "\n",
        "X_train = X_train.reshape(402,120,160,1)\n",
        "X_train.shape\n",
        "# plt.matshow(X_train[0])\n",
        "\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "my_training_batch_generator = My_Custom_Generator(X_train, y_train, batch_size)\n",
        "my_validation_batch_generator = My_Custom_Generator(X_test,y_test, batch_size)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbBrLAAzhg9c",
        "outputId": "e24d0ebb-c826-4696-824b-247b3490920d"
      },
      "source": [
        "#MODEL\n",
        "model = keras.Sequential([\n",
        "    #cnn layers\n",
        "    keras.layers.Conv2D(filters=32,kernel_size=(3, 3),activation='relu',input_shape=(120,160,1)),\n",
        "    keras.layers.MaxPooling2D((2,2)),\n",
        "\n",
        "    keras.layers.Conv2D(filters=64,kernel_size=(3, 3),activation='relu'),\n",
        "    keras.layers.MaxPooling2D((2,2)),\n",
        "\n",
        "    #dense normal ann\n",
        "    keras.layers.Flatten(),     \n",
        "    \n",
        "    keras.layers.Dense(60,activation='relu'),\n",
        "    \n",
        "    keras.layers.Dense(4,activation='softmax'),\n",
        "    #softmax normalises the probability of the output set\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss = 'sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "#model.fit(X_train,y_train,epochs=20)\n",
        "model.fit_generator(generator=my_training_batch_generator, steps_per_epoch = int(402 // batch_size), epochs = 10, verbose = 1,\n",
        "                    validation_data = my_validation_batch_generator, validation_steps = int(198 // batch_size))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 1.5152 - accuracy: 0.2487 - val_loss: 1.3865 - val_accuracy: 0.2602\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 1.3812 - accuracy: 0.3141 - val_loss: 1.3883 - val_accuracy: 0.2347\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 1.3470 - accuracy: 0.3794 - val_loss: 1.4163 - val_accuracy: 0.2500\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 1.2485 - accuracy: 0.4648 - val_loss: 1.4755 - val_accuracy: 0.2653\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 1.0841 - accuracy: 0.5503 - val_loss: 1.5759 - val_accuracy: 0.2653\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.8774 - accuracy: 0.6307 - val_loss: 1.7851 - val_accuracy: 0.2500\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6557 - accuracy: 0.7688 - val_loss: 2.3541 - val_accuracy: 0.2806\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.4145 - accuracy: 0.8392 - val_loss: 2.8132 - val_accuracy: 0.2704\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.2428 - accuracy: 0.9246 - val_loss: 3.6847 - val_accuracy: 0.2551\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.1418 - accuracy: 0.9548 - val_loss: 4.2867 - val_accuracy: 0.2398\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff6ecb86c10>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goZQ_0EShhqA",
        "outputId": "91af5762-3b10-4570-bce9-cf3b2af0b20e"
      },
      "source": [
        "#EVALUATION\n",
        "X_test = X_test.reshape(198,120,160,1)\n",
        "model.evaluate(X_test,y_test)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 12ms/step - loss: 2.7062 - accuracy: 0.1970\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.7062370777130127, 0.19696970283985138]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}